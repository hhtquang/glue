import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark._
import org.apache.spark.sql.SparkSession      


object csvtos31 {
  def main(args: Array[String]) {
    
    val spark = SparkSession.builder.appName("WriteS3").getOrCreate()
  
    //Fist change 
      
    //read csv with options
    val df = spark.read.options(Map("inferSchema"->"true","delimiter"->",","header"->"true")).csv("s3://huynqsecondbucket/input/testtrigger1/compressor_downtime_1467555_1.csv")
    df.write.parquet("s3://huynqsecondbucket/input/testtrigger1/compressor_downtime_1467555_1.parquet")
  }
}